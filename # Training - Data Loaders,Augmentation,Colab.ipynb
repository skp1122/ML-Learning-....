{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - Data Loaders,Augmentation,Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cats_Dogs_Humans_Horses_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download on Colab....copy the link from dropbox and run the below code:-\n",
    "!wget https://www.dropbox.com/sh/2idonozs741hzkr/AABXT1P1U-1f4L_VdS4wY06ca?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzipping the data via folder name\n",
    "!unzip AABXT1P1U-1f4L_VdS4wY06ca?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeing the directries\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "folders = os.listdir(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for validation generator\\\n",
    "\n",
    "if not os.path.isdir(\"val_images\"):\n",
    "    os.mkdir(\"val_images\")\n",
    "classes = [\"dogs\",\"cats\",\"horses\",\"humans\"]\n",
    "\n",
    "for c in classes:\n",
    "    p = os.path.join(\"val_images\",c)\n",
    "    if not p:\n",
    "        os.mkdir(p)\n",
    "        \n",
    "SPLIT = 0.9\n",
    "\n",
    "for f in os.listdir(\"images\"):\n",
    "    path = \"images/\"+f\n",
    "    imgs = os.listdir(path)\n",
    "    \n",
    "    split_size = int(SPLIT*len(imgs))\n",
    "    files_to_move = imgs[split_size:]\n",
    "    #print(len(files_to_move))\n",
    "    #print(filse_to_move)\n",
    "    \n",
    "    for img_f in files_to_move:\n",
    "        src = os.path.join(path,img_f)\n",
    "        dest = os.path.join(\"val_images/\"+f,img_f)\n",
    "        shutil.move(src.dest)\n",
    "        #print(src)\n",
    "        Eprint(dest)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Data\")\n",
    "for f in folders:\n",
    "    path = \"images/\"+f # exact path of folder\n",
    "    print(f+\" \"+str(len(os.listdir(path))))\n",
    "    \n",
    "print(\"Validation Data\")\n",
    "for f in folders:\n",
    "    path = \"val_images/\"+f\n",
    "    print(f+\" \"+str(len(os.listdir(path))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = \"images/cats/cat.1.jpg\"\n",
    "img = image.load_img(sample_path)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = image.img_to_array(img)/255.0\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Convolution2D,MaxPooling2D,Flatten,Dense,Dropout\n",
    "from keras.utlis import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Convolution2D(64,(3,3),activation='relu'),input_shape=(28,28,1))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Convolution2D(64,(3,3),activation='relu'),input_shape=(28,28,1))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Convolution2D(64,(3,3),activation='relu'),input_shape=(28,28,1))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "adm = optimizers.adam(lr=1e-4)\n",
    "model.compile(loss'categorical_crossentropy',optimizer=adm,metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(___) is useful when dataset is small and it can fit inside the memory\n",
    "\n",
    "# train generator\n",
    "train_gen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    \"images/\",\n",
    "    target_size = (150,150),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "# validation generator\n",
    "val_gen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "val_generator = val_gen.flow_from_directory(\n",
    "    \"val_images/\",\n",
    "    target_size = (150,150),\n",
    "    batch_size = 32,\n",
    "    class_mose = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_generator.next()\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "x_,y_ = val_generator.next()\n",
    "print(x_.shape)\n",
    "print(y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in train_generator:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "for x,y in val_generator:\n",
    "    print(x.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our model\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs = 60,\n",
    "    steps_per_epoch = 7,\n",
    "    validation_data = val_generator,\n",
    "    validation_steps = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising\n",
    "\n",
    "plt.plot(train_acc,label=\"Training Accuracy\")\n",
    "plt.plot(val_acc,label= \"Val Accuracy\")\n",
    "plt.plot(train_loss,label=\"Training Loss\")\n",
    "plt.plot(val_loss,label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning - Data Augmentation and Image Pipelines\n",
    "- Real life dataset can be large or small\n",
    "- Image Pipelines are an efficient way to handle large datasets\n",
    "- Data Augmentation is technique of augmenting data, which acts as a regularizer hence reduces overlifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny Imagenet 200 - It contains 1 lac images and 200 class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(\n",
    "    rescale = 1/255.0,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.3,\n",
    "    horizontal_flip = True,\n",
    ")\n",
    "\n",
    "test_gen = Image_dataGenerator(\n",
    "    rescale = 1/255.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_image_gen.flow_from_directory(\n",
    "    \"tiny-imgaenet-200/train\",\n",
    "    target_size=((224,224)),\n",
    "    batch_size = 128,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = trian_image_gen.flow_from_directory(\n",
    "    \"tiny-imgenet-200/val\",\n",
    "    target_size=((224,224)),\n",
    "    bach_size = 128,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,y) in train_gen:\n",
    "    print(x.shape,y.shape)\n",
    "    \n",
    "    for i in range(10):\n",
    "        plt.imshow(x[i])\n",
    "        plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = train_gen.class_indices\n",
    "print(class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation_data(target_size,no_of_classes):\n",
    "    with open(os.path.join(\"tiny-imagenet-200/val/\",\"val_annotations.txt\")) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        m = len(lines)\n",
    "        X = np.empty((m,*target_size,3)) # B, W, H, 3\n",
    "        y = np.empty(m)\n",
    "        \n",
    "        for i,line in enumerate(lines):\n",
    "            tokens = line.split()\n",
    "            img_name = token[0]\n",
    "            img_label = token[1]\n",
    "            \n",
    "            img_url = os.path.join(\"tiny-imagenet-200/val\",img_name)\n",
    "            img = image.open(img_url)\n",
    "            img = img.resize(target_size)\n",
    "            X[i,] = np.array(img,dtype=np.float32)/255.0\n",
    "            img.close()\n",
    "            y[i] = class_ids[img_label]\n",
    "            \n",
    "        return X,keras.utils.to_categorical(y,num_classes=no_of_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val ,Y_val = load_validation_data((224,224),200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
